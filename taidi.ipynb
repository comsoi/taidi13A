{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T10:24:46.868251Z",
     "start_time": "2023-04-18T10:24:46.851592Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T10:24:47.996783Z",
     "start_time": "2023-04-18T10:24:47.951631Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def encode_detect(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return chardet.detect(f.read())['encoding']\n",
    "\n",
    "def read_file(file):\n",
    "    print(\"Reading file: {}\".format(file))\n",
    "    return pd.read_csv(file, encoding=encode_detect(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:51:30.127600Z",
     "start_time": "2023-04-18T01:50:38.523747Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: data/all/附件6.csv\n",
      "Reading file: data/all/附件5\\20221001.csv\n",
      "Reading file: data/all/附件5\\20221002.csv\n",
      "Reading file: data/all/附件5\\20221003.csv\n",
      "Reading file: data/all/附件5\\20221004.csv\n",
      "Reading file: data/all/附件5\\20221005.csv\n",
      "Reading file: data/all/附件5\\20221006.csv\n",
      "Reading file: data/all/附件5\\20221007.csv\n",
      "Reading file: data/all/附件5\\20221008.csv\n",
      "Reading file: data/all/附件5\\20221009.csv\n",
      "Reading file: data/all/附件5\\20221010.csv\n",
      "Reading file: data/all/附件5\\20221011.csv\n",
      "Reading file: data/all/附件5\\20221012.csv\n",
      "Reading file: data/all/附件5\\20221013.csv\n",
      "Reading file: data/all/附件5\\20221014.csv\n",
      "Reading file: data/all/附件5\\20221015.csv\n",
      "Reading file: data/all/附件5\\20221016.csv\n",
      "Reading file: data/all/附件5\\20221017.csv\n",
      "Reading file: data/all/附件5\\20221018.csv\n",
      "Reading file: data/all/附件5\\20221019.csv\n",
      "Reading file: data/all/附件5\\20221020.csv\n",
      "Reading file: data/all/附件5\\20221021.csv\n",
      "Reading file: data/all/附件5\\20221022.csv\n",
      "Reading file: data/all/附件5\\20221023.csv\n",
      "Reading file: data/all/附件5\\20221024.csv\n",
      "Reading file: data/all/附件5\\20221025.csv\n",
      "Reading file: data/all/附件5\\20221026.csv\n",
      "Reading file: data/all/附件5\\20221027.csv\n",
      "Reading file: data/all/附件5\\20221028.csv\n",
      "Reading file: data/all/附件5\\20221029.csv\n",
      "Reading file: data/all/附件5\\20221030.csv\n",
      "Reading file: data/all/附件5\\20221031.csv\n",
      "Reading file: data/all/附件5\\20221101.csv\n",
      "Reading file: data/all/附件5\\20221102.csv\n",
      "Reading file: data/all/附件5\\20221103.csv\n",
      "Reading file: data/all/附件5\\20221104.csv\n",
      "Reading file: data/all/附件5\\20221105.csv\n",
      "Reading file: data/all/附件5\\20221106.csv\n",
      "Reading file: data/all/附件5\\20221107.csv\n",
      "Reading file: data/all/附件5\\20221108.csv\n",
      "Reading file: data/all/附件5\\20221109.csv\n",
      "Reading file: data/all/附件5\\20221110.csv\n",
      "Reading file: data/all/附件5\\20221111.csv\n",
      "Reading file: data/all/附件5\\20221112.csv\n",
      "Reading file: data/all/附件5\\20221113.csv\n",
      "Reading file: data/all/附件5\\20221114.csv\n",
      "Reading file: data/all/附件5\\20221115.csv\n",
      "Reading file: data/all/附件5\\20221116.csv\n",
      "Reading file: data/all/附件5\\20221117.csv\n",
      "Reading file: data/all/附件5\\20221118.csv\n",
      "Reading file: data/all/附件5\\20221119.csv\n",
      "Reading file: data/all/附件5\\20221120.csv\n",
      "Reading file: data/all/附件5\\20221121.csv\n",
      "Reading file: data/all/附件5\\20221122.csv\n",
      "Reading file: data/all/附件5\\20221123.csv\n",
      "Reading file: data/all/附件5\\20221124.csv\n",
      "Reading file: data/all/附件5\\20221125.csv\n",
      "Reading file: data/all/附件5\\20221126.csv\n",
      "Reading file: data/all/附件5\\20221127.csv\n",
      "Reading file: data/all/附件5\\20221128.csv\n",
      "Reading file: data/all/附件5\\20221129.csv\n",
      "Reading file: data/all/附件5\\20221130.csv\n",
      "Reading file: data/all/附件2.csv\n",
      "Reading file: data/all/附件3.csv\n",
      "Reading file: data/all/附件4.csv\n",
      "Reading file: data/exp/附件1/result1.csv\n",
      "Reading file: data/exp/附件1/result2.csv\n"
     ]
    }
   ],
   "source": [
    "df_na_check = read_file('data/all/附件6.csv')  # 读取核酸采样检测信息表\n",
    "\n",
    "file_list = glob.glob('data/all/附件5/*.csv')\n",
    "df_scan = pd.concat([read_file(file) for file in file_list])  # 读取场所扫码信息表\n",
    "df_scan['create_time'] =  pd.to_datetime(df_scan['create_time'])\n",
    "\n",
    "df_people = read_file('data/all/附件2.csv')  # 读取人员信息表\n",
    "df_place = read_file('data/all/附件3.csv')  # 读取场所信息表\n",
    "\n",
    "df_self_check = read_file('data/all/附件4.csv')  # 读取个人自查上报信息表\n",
    "df_self_check['dump_time'] = pd.to_datetime(df_self_check['dump_time'])\n",
    "# 提交示例1\n",
    "result1 = read_file('data/exp/附件1/result1.csv')\n",
    "# 提交示例2\n",
    "result2 = read_file('data/exp/附件1/result2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:49:14.523946Z",
     "start_time": "2023-04-16T18:49:14.460438Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>密接者ID</th>\n",
       "      <th>密接日期</th>\n",
       "      <th>密接场所ID</th>\n",
       "      <th>阳性人员ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   序号  密接者ID  密接日期  密接场所ID  阳性人员ID\n",
       "0   1    NaN   NaN     NaN     NaN\n",
       "1   2    NaN   NaN     NaN     NaN\n",
       "2   3    NaN   NaN     NaN     NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看提交示例\n",
    "result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T10:28:08.188626Z",
     "start_time": "2023-04-18T10:28:08.091794Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>次密接者ID</th>\n",
       "      <th>次密接日期</th>\n",
       "      <th>次密接场所ID</th>\n",
       "      <th>密接者ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   序号  次密接者ID  次密接日期  次密接场所ID  密接者ID\n",
       "0   1     NaN    NaN      NaN    NaN\n",
       "1   2     NaN    NaN      NaN    NaN\n",
       "2   3     NaN    NaN      NaN    NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看提交示例\n",
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:50:33.282641Z",
     "start_time": "2023-04-16T18:50:33.238475Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据描述性统计\n",
    "def summary_stats_table(data):\n",
    "    '''\n",
    "    a function to summerize all types of data\n",
    "    分类型按列的数据分布与异常值统计\n",
    "    '''\n",
    "    # count of nulls\n",
    "    # 空值数量\n",
    "    missing_counts = pd.DataFrame(data.isnull().sum())\n",
    "    missing_counts.columns = ['count_null']\n",
    "\n",
    "    # numeric column stats\n",
    "    # 数值列数据分布统计\n",
    "    num_stats = data.select_dtypes(include=['int64','float64']).describe().loc[['count','min','max','25%','50%','75%']].transpose()\n",
    "    num_stats['dtype'] = data.select_dtypes(include=['int64','float64']).dtypes.tolist()\n",
    "\n",
    "    # non-numeric value stats\n",
    "    # 非数值列数据分布统计\n",
    "    non_num_stats = data.select_dtypes(exclude=['int64','float64']).describe().transpose()\n",
    "    non_num_stats['dtype'] = data.select_dtypes(exclude=['int64','float64']).dtypes.tolist()\n",
    "    non_num_stats = non_num_stats.rename(columns={\"first\": \"min\", \"last\": \"max\"})\n",
    "\n",
    "    # merge all\n",
    "    # 聚合结果\n",
    "    stats_merge = pd.concat([num_stats, non_num_stats], axis=0, join='outer', ignore_index=False, keys=None,\n",
    "              levels=None, names=None, verify_integrity=False, copy=True, sort=False).fillna(\"\").sort_values('dtype')\n",
    "\n",
    "    column_order = ['dtype', 'count', 'count_null','unique','min','max','25%','50%','75%','top','freq']\n",
    "    summary_stats = pd.merge(stats_merge, missing_counts, left_index=True, right_index=True, sort=False)[column_order]\n",
    "    return(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:50:39.600923Z",
     "start_time": "2023-04-16T18:50:39.336775Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>24999.75</td>\n",
       "      <td>49998.5</td>\n",
       "      <td>74997.25</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>float64</td>\n",
       "      <td>99985.0</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>-7.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openid</th>\n",
       "      <td>object</td>\n",
       "      <td>98028.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>98028</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>oESgL4Kw2tG7yZWlxdgHv4TkSgFN8Ibza6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>object</td>\n",
       "      <td>99965.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>男</td>\n",
       "      <td>52656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation</th>\n",
       "      <td>object</td>\n",
       "      <td>99621.0</td>\n",
       "      <td>375</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>汉族</td>\n",
       "      <td>95942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birthdate</th>\n",
       "      <td>object</td>\n",
       "      <td>99978.0</td>\n",
       "      <td>18</td>\n",
       "      <td>26959</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2005/11/6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create_time</th>\n",
       "      <td>object</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99918</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-02-12 08:50:45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dtype    count  count_null unique  min      max       25%  \\\n",
       "user_id        int64  99996.0           0         1.0  99996.0  24999.75   \n",
       "age          float64  99985.0          11        -7.0    982.0      22.0   \n",
       "openid        object  98028.0        1968  98028                           \n",
       "gender        object  99965.0          31      2                           \n",
       "nation        object  99621.0         375     10                           \n",
       "birthdate     object  99978.0          18  26959                           \n",
       "create_time   object  99996.0           0  99918                           \n",
       "\n",
       "                 50%       75%                                 top   freq  \n",
       "user_id      49998.5  74997.25                                             \n",
       "age             37.0      51.0                                             \n",
       "openid                          oESgL4Kw2tG7yZWlxdgHv4TkSgFN8Ibza6      1  \n",
       "gender                                                           男  52656  \n",
       "nation                                                          汉族  95942  \n",
       "birthdate                                                2005/11/6     16  \n",
       "create_time                                    2022-02-12 08:50:45      2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats_table(df_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**数据说明**\n",
    "- user_id：人员 ID，用于唯一标识一个人员。\n",
    "- openid：微信 OpenID，用于关联该人员的微信账号信息。\n",
    "- gender：人员的性别，可选值为“男”或“女”。\n",
    "- nation：人员所属的民族，如汉族、蒙古族、藏族等。\n",
    "- age：人员的年龄，以整数表示。\n",
    "- birthdate：人员的出生日期，格式一般为“YYYY-MM-DD”。\n",
    "- create_time：该记录的创建时间，用于记录人员信息的更新时间。\n",
    "\n",
    "\n",
    "**以下分析结果均基于全量数据**\n",
    "\n",
    "用户总共有99996条数据。\n",
    "\n",
    "- 年龄区间是[-7，982]\n",
    "\n",
    "    Tips:年龄跨度异常大，可能存在异常值，例如负数的年龄。需要进一步检查并处理异常值。\n",
    "    Tips:年龄跨度比较大，自然而然，我们可以根据年龄做特征工程。\n",
    "\n",
    "- 在gender中，总共有2个类别，但是实际数据中有31个缺失值。\n",
    "\n",
    "    Tips:需要处理缺失值，例如用众数填充或将其标记为“未知”。\n",
    "\n",
    "- nation民族总共有10个类别，其中汉族占比最高，达到95942。\n",
    "\n",
    "    Tips:在全量数据中，可以考虑将民族特征进行独热编码或分组处理，以便于分析和建模。\n",
    "    Tips:如果后续需要用到该列进行聚合分析或特征工程，可以在Baseline中写好动态的代码。\n",
    "\n",
    "\n",
    "- birthdate列中有18个缺失值，需要处理这些缺失值。\n",
    "\n",
    "    Tips:可以考虑使用平均值、中位数或众数等方法填充缺失值。\n",
    "\n",
    "- create_time列没有缺失值，但是需要注意数据类型为object。\n",
    "\n",
    "    Tips:将create_time转换为日期类型，以便于进一步处理和分析。\n",
    "    Tips:注意关注时间的始末，与其它相关联的时间进行比较，这样可以挖掘出更多信息或筛选出一些异常情况。\n",
    "\n",
    "根据上述分析，我们可以得出以下建议：\n",
    "\n",
    "检查并处理年龄列中的异常值，例如负数。\n",
    "处理gender、birthdate等列中的缺失值，例如使用众数填充或将其标记为“未知”。\n",
    "将日期相关列（如birthdate和create_time）的数据类型转换为日期类型。\n",
    "对民族特征进行独热编码或分组处理，以便于分析和建模。\n",
    "考虑根据已有数据生成新的特征，例如年龄段或根据birthdate和create_time计算用户的年龄。\n",
    "\n",
    "\n",
    "- birthdate和create_time在这里都是对应着50个不一样的时间\n",
    "\n",
    "    Tips:注意关注时间的始末，与其它相关联的时间进行比较，这样可以挖掘出更多信息或筛选出一些异常情况。\n",
    "\n",
    "         在全量数据中，时间大概率是有重复值的，也要考虑重复时间是否对解题有一定的影响亦或者重复时间的含义。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:37:22.138449Z",
     "start_time": "2023-04-16T22:37:22.044090Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>grid_point_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>737.5</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2210.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_coordinate</th>\n",
       "      <td>float64</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>34.79</td>\n",
       "      <td>29320.01</td>\n",
       "      <td>9973.45</td>\n",
       "      <td>12565.56</td>\n",
       "      <td>15029.45</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_coordinate</th>\n",
       "      <td>float64</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>10.76</td>\n",
       "      <td>29710.22</td>\n",
       "      <td>9521.09</td>\n",
       "      <td>12054.57</td>\n",
       "      <td>14700.45</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>object</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2947</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>宾馆旅店1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_type</th>\n",
       "      <td>object</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>娱乐</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create_time</th>\n",
       "      <td>object</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2942</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2020/5/23 6:08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dtype   count  count_null unique    min       max      25%  \\\n",
       "grid_point_id    int64  2947.0           0           1.0    2947.0    737.5   \n",
       "x_coordinate   float64  2947.0           0         34.79  29320.01  9973.45   \n",
       "y_coordinate   float64  2947.0           0         10.76  29710.22  9521.09   \n",
       "name            object  2947.0           0   2947                             \n",
       "point_type      object  2947.0           0     18                             \n",
       "create_time     object  2947.0           0   2942                             \n",
       "\n",
       "                    50%       75%             top freq  \n",
       "grid_point_id    1474.0    2210.5                       \n",
       "x_coordinate   12565.56  15029.45                       \n",
       "y_coordinate   12054.57  14700.45                       \n",
       "name                                        宾馆旅店1    1  \n",
       "point_type                                     娱乐  400  \n",
       "create_time                        2020/5/23 6:08    2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats_table(df_place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**数据说明**\n",
    "- grid_point_id：场所 ID，用于唯一标识一个场所。\n",
    "- name：场所的名称，如公司、餐厅、超市等。\n",
    "- point_type：场所的类型，如商业、娱乐、文化、医疗等。\n",
    "- x_coordinate：场所的 X 坐标，以米为单位，用于表示场所在地图上的位置。\n",
    "- y_coordinate：场所的 Y 坐标，以米为单位，用于表示场所在地图上的位置。\n",
    "- create_time：该记录的创建时间，用于记录场所信息的更新时间。\n",
    "\n",
    "\n",
    "**以下分析结果均基于全量数据**\n",
    "\n",
    "场所总共有2947条数据。\n",
    "- 坐标区间：\n",
    "    x_coordinate范围在[34.79, 29320.01]之间。\n",
    "    y_coordinate范围在[10.76, 29710.22]之间。\n",
    "    Tips:可以根据X、Y坐标对其它特征进行可视化\n",
    "\n",
    "- 在name列中，共有2947个不同的名称。\n",
    "\n",
    "    Tips:可以考虑对场所名称进行文本分析，提取关键词，以了解场所的具体业务或属性。\n",
    "\n",
    "- 在point_type中，总共有18个类别，娱乐类场所数量最多，共有400个。\n",
    "\n",
    "    Tips:可以对不同类型的场所进行分析，以了解各类场所的分布情况和特点。可以根据这一列特征做更多的数据分析，或许还可以进行特征工程。\n",
    "\n",
    "- create_time列没有缺失值，但是需要注意数据类型为object。\n",
    "\n",
    "    Tips:将create_time转换为日期类型，以便于进一步处理和分析。\n",
    "\n",
    "根据上述分析，我们可以得出以下建议：\n",
    "\n",
    "计算场所之间的距离，以便于分析不同类型场所的分布情况。\n",
    "对场所名称进行文本分析，提取关键词，以了解场所的具体业务或属性。\n",
    "对不同类型的场所进行分析，以了解各类场所的分布情况和特点。\n",
    "将日期相关列（如create_time）的数据类型转换为日期类型。\n",
    "考虑根据已有数据生成新的特征，例如基于场所类型的分组统计或根据坐标信息计算密度等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:42:59.378322Z",
     "start_time": "2023-04-16T22:42:59.261985Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sno</th>\n",
       "      <td>int64</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>18684.75</td>\n",
       "      <td>37368.5</td>\n",
       "      <td>56052.25</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>14.0</td>\n",
       "      <td>99992.0</td>\n",
       "      <td>24648.0</td>\n",
       "      <td>49721.0</td>\n",
       "      <td>74849.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symptom</th>\n",
       "      <td>int64</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nucleic_acid_result</th>\n",
       "      <td>int64</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resident_flag</th>\n",
       "      <td>int64</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_coordinate</th>\n",
       "      <td>float64</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.6</td>\n",
       "      <td>19999.48</td>\n",
       "      <td>5010.8875</td>\n",
       "      <td>10001.76</td>\n",
       "      <td>15018.6775</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_coordinate</th>\n",
       "      <td>float64</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.21</td>\n",
       "      <td>19999.91</td>\n",
       "      <td>4991.1975</td>\n",
       "      <td>9950.215</td>\n",
       "      <td>14929.6225</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dump_time</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>74736.0</td>\n",
       "      <td>0</td>\n",
       "      <td>73830</td>\n",
       "      <td>2022-10-01 07:01:18</td>\n",
       "      <td>2022-11-30 22:59:58</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-10-28 18:34:35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dtype    count  count_null unique  \\\n",
       "sno                            int64  74736.0           0          \n",
       "user_id                        int64  74736.0           0          \n",
       "symptom                        int64  74736.0           0          \n",
       "nucleic_acid_result            int64  74736.0           0          \n",
       "resident_flag                  int64  74736.0           0          \n",
       "x_coordinate                 float64  74736.0           0          \n",
       "y_coordinate                 float64  74736.0           0          \n",
       "dump_time             datetime64[ns]  74736.0           0  73830   \n",
       "\n",
       "                                      min                  max        25%  \\\n",
       "sno                                   1.0              74736.0   18684.75   \n",
       "user_id                              14.0              99992.0    24648.0   \n",
       "symptom                               1.0                  8.0        8.0   \n",
       "nucleic_acid_result                   0.0                  1.0        0.0   \n",
       "resident_flag                         1.0                  2.0        1.0   \n",
       "x_coordinate                          0.6             19999.48  5010.8875   \n",
       "y_coordinate                         0.21             19999.91  4991.1975   \n",
       "dump_time             2022-10-01 07:01:18  2022-11-30 22:59:58              \n",
       "\n",
       "                           50%         75%                 top freq  \n",
       "sno                    37368.5    56052.25                 NaT       \n",
       "user_id                49721.0     74849.0                 NaT       \n",
       "symptom                    8.0         8.0                 NaT       \n",
       "nucleic_acid_result        0.0         0.0                 NaT       \n",
       "resident_flag              1.0         1.0                 NaT       \n",
       "x_coordinate          10001.76  15018.6775                 NaT       \n",
       "y_coordinate          9950.215  14929.6225                 NaT       \n",
       "dump_time                                  2022-10-28 18:34:35    3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats_table(df_self_check)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**数据说明**\n",
    "- sno：序列号，用于唯一标识一条自查记录。\n",
    "- user_id：人员 ID，对应于“人员信息表”中的 user_id，用于关联自查记录与相应的人员。\n",
    "- x_coordinate：上报地点的 X 坐标，以米为单位，用于表示上报地点在地图上的位置。\n",
    "- y_coordinate：上报地点的 Y 坐标，以米为单位，用于表示上报地点在地图上的位置。\n",
    "- symptom：症状，用于记录自查者的症状情况。可选值为：1 发热、2 乏力、3 干咳、4 鼻塞、5 流涕、6 腹泻、7 呼吸困难、8 无症状。\n",
    "- nucleic_acid_result：核酸检测结果，用于记录自查者的核酸检测情况。可选值为：0 阴性、1 阳性、2 未知（非必填）。\n",
    "- resident_flag：是否常住居民，用于记录自查者的居住情况。可选值为：0 未知、1 是、2 否。\n",
    "- dump_time：上报时间，用于记录自查记录的上报时间。\n",
    "\n",
    "\n",
    "**以下分析结果均基于全量数据**\n",
    "\n",
    "自查记录总共有74736条数据。\n",
    "\n",
    "- 这里的X，Y坐标和上表的并不一样，可以挖掘一下两者的区别\n",
    "    坐标区间：\n",
    "\n",
    "    x_coordinate范围在[0.6, 19999.48]之间。\n",
    "    y_coordinate范围在[0.21, 19999.91]之间。\n",
    "    Tips:可以根据坐标信息计算上报地点之间的距离，以便于分析不同地区的自查情况。\n",
    "\n",
    "- 在symptom列中，共有8种症状。\n",
    "\n",
    "    Tips:可以对不同症状进行分析，以了解自查者的症状分布情况。可以考虑先写好数据分析可视化的代码。\n",
    "\n",
    "    这一列特征还有一个特点是，在特征工程的时候，可以很好的和其它特征衍生出很多可解释性的交叉特征（eg:symptom-nucleic_acid_result）\n",
    "\n",
    "    在nucleic_acid_result中，总共有3种结果，其中阴性结果占多数。\n",
    "    在resident_flag中，共有3种情况，其中常住居民占多数。\n",
    "- nucleic_acid_result,resident_flag同理\n",
    "\n",
    "\n",
    "- dump_time列没有缺失值，数据类型为datetime64[ns]。\n",
    "\n",
    "    Tips:可以分析不同时间段的自查情况，例如按天、周或月统计。\n",
    "\n",
    "根据上述分析，我们可以得出以下建议：\n",
    "\n",
    "计算上报地点之间的距离，以便于分析不同地区的自查情况。\n",
    "对不同症状进行分析，以了解自查者的症状分布情况。\n",
    "对核酸检测结果进行分析，了解自查者中阳性和阴性的比例。\n",
    "分析常住居民和非常住居民的自查情况，以了解不同人群的自查行为。\n",
    "分析不同时间段的自查情况，例如按天、周或月统计。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:50:56.823429Z",
     "start_time": "2023-04-16T22:50:43.256874Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sno</th>\n",
       "      <td>int64</td>\n",
       "      <td>24353780.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>415327.0</td>\n",
       "      <td>99811.0</td>\n",
       "      <td>199622.0</td>\n",
       "      <td>299432.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_point_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>24353780.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>24353780.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>24996.0</td>\n",
       "      <td>50053.0</td>\n",
       "      <td>75017.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>float64</td>\n",
       "      <td>24353780.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>35.7</td>\n",
       "      <td>37.2</td>\n",
       "      <td>36.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>36.8</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create_time</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>24353780.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4538584</td>\n",
       "      <td>2022-10-01 05:30:00</td>\n",
       "      <td>2022-12-01 04:47:59</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-10-21 11:55:43</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dtype       count  count_null   unique  \\\n",
       "sno                     int64  24353780.0           0            \n",
       "grid_point_id           int64  24353780.0           0            \n",
       "user_id                 int64  24353780.0           0            \n",
       "temperature           float64  24353780.0           0            \n",
       "create_time    datetime64[ns]  24353780.0           0  4538584   \n",
       "\n",
       "                               min                  max      25%       50%  \\\n",
       "sno                            1.0             415327.0  99811.0  199622.0   \n",
       "grid_point_id                  1.0               2947.0    751.0    1503.0   \n",
       "user_id                        1.0              99996.0  24996.0   50053.0   \n",
       "temperature                   35.7                 37.2     36.1      36.4   \n",
       "create_time    2022-10-01 05:30:00  2022-12-01 04:47:59                      \n",
       "\n",
       "                    75%                 top freq  \n",
       "sno            299432.0                 NaT       \n",
       "grid_point_id    2225.0                 NaT       \n",
       "user_id         75017.0                 NaT       \n",
       "temperature        36.8                 NaT       \n",
       "create_time             2022-10-21 11:55:43   26  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats_table(df_scan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**数据说明**\n",
    "- sno：序列号，用于唯一标识一条扫码记录。\n",
    "- grid_point_id：场所 ID，对应于“场所信息表”中的 grid_point_id，用于关联扫码记录与相应的场所。\n",
    "- user_id：人员 ID，对应于“人员信息表”中的 user_id，用于关联扫码记录与相应的人员。\n",
    "- temperature：体温，用于记录扫码者的体温情况。\n",
    "- create_time：扫码记录时间，用于记录扫码记录的时间戳。\n",
    "\n",
    "\n",
    "**以下分析结果均基于全量数据**\n",
    "\n",
    "扫码记录总共有24,353,780条数据。\n",
    "\n",
    "- 体温范围在[35.7, 37.2]之间。\n",
    "\n",
    "    Tips:可以对不同体温范围的人数进行统计，以了解体温分布情况。在实际数据中，可能会有更高或更低的体温值，需要在分析时考虑这些异常值。\n",
    "\n",
    "- create_time（扫码记录时间）:\n",
    "\n",
    "    Tips: 可以分析不同时间段的扫码情况，例如按天、周或月统计。此外，可以将扫码记录时间与个人自查上报信息表的上报时间以及采样日期进行比较，以了解扫码行为与自查行为之间的关联。\n",
    "\n",
    "根据上述分析，我们可以得出以下建议：\n",
    "\n",
    "对不同体温范围的人数进行统计，以了解体温分布情况。注意考虑实际数据中可能存在的异常值。\n",
    "分析不同时间段的扫码情况，例如按天、周或月统计。\n",
    "将扫码记录时间与个人自查上报信息表的上报时间以及采样日期进行比较，以了解扫码行为与自查行为之间的关联。\n",
    "结合场所信息和人员信息，分析不同场所、人群的扫码行为，以了解场所类型和人群特征对扫码行为的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:56:46.400927Z",
     "start_time": "2023-04-16T22:56:41.065017Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sno</th>\n",
       "      <td>int64</td>\n",
       "      <td>3967851.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>3985187.0</td>\n",
       "      <td>991528.5</td>\n",
       "      <td>1986191.0</td>\n",
       "      <td>2984163.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>3967851.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>99996.0</td>\n",
       "      <td>24994.0</td>\n",
       "      <td>50001.0</td>\n",
       "      <td>74992.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_point_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>3967851.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>58.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>2183.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cysj</th>\n",
       "      <td>object</td>\n",
       "      <td>3967851.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1121300</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-11-20 11:39:55</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jcsj</th>\n",
       "      <td>object</td>\n",
       "      <td>3967851.0</td>\n",
       "      <td>0</td>\n",
       "      <td>787289</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2022-11-17 01:51:06</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jg</th>\n",
       "      <td>object</td>\n",
       "      <td>3967851.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>阴性</td>\n",
       "      <td>3966819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dtype      count  count_null   unique   min        max  \\\n",
       "sno             int64  3967851.0           0            1.0  3985187.0   \n",
       "user_id         int64  3967851.0           0            1.0    99996.0   \n",
       "grid_point_id   int64  3967851.0           0           58.0     2891.0   \n",
       "cysj           object  3967851.0           0  1121300                    \n",
       "jcsj           object  3967851.0           0   787289                    \n",
       "jg             object  3967851.0           0        2                    \n",
       "\n",
       "                    25%        50%        75%                  top     freq  \n",
       "sno            991528.5  1986191.0  2984163.5                                \n",
       "user_id         24994.0    50001.0    74992.0                                \n",
       "grid_point_id     766.0     1475.0     2183.0                                \n",
       "cysj                                           2022-11-20 11:39:55       16  \n",
       "jcsj                                           2022-11-17 01:51:06       19  \n",
       "jg                                                              阴性  3966819  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats_table(df_na_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**数据说明**\n",
    "- sno：序列号，用于唯一标识一条核酸采样记录。\n",
    "- user_id：人员 ID，对应于“人员信息表”中的 user_id，用于关联核酸采样记录与相应的人员。\n",
    "- cysj：采样日期和时间，用于记录核酸采样的日期和时间。\n",
    "- jcsj：检测日期和时间，用于记录核酸检测的日期和时间。\n",
    "- jg：检测结果，用于记录核酸检测的结果。可选值为：阴性、阳性、未知。\n",
    "- grid_point_id：场所 ID，对应于“场所信息表”中的 grid_point_id，用于关联核酸采样记录与相应的场所。\n",
    "\n",
    "\n",
    "**以下分析结果均基于全量数据**\n",
    "\n",
    "核酸采样记录总共有3,967,851条数据。\n",
    "\n",
    "- 采样时间（cysj）与检测时间（jcsj）的关系：按照逻辑来说，检测时间应该晚于采样时间。可以通过对比这两个时间来判断数据是否异常。\n",
    "\n",
    "    Tips:在实际数据分析中，可能会出现异常值，如检测时间早于采样时间的情况。这些异常值需要在分析时进行处理。\n",
    "\n",
    "- 检测结果（jg）分布：示例数据中检测结果均为阴性。\n",
    "\n",
    "    Tips:实际数据中可能包含阴性、阳性和未知三种结果。在进行数据分析时，需要考虑各种结果的分布情况。\n",
    "\n",
    "根据上述分析，我们可以得出以下建议：\n",
    "\n",
    "对比采样时间（cysj）与检测时间（jcsj），找出可能的异常值并进行处理。\n",
    "分析检测结果（jg）的分布情况，了解阴性、阳性和未知结果的比例。\n",
    "结合场所信息和人员信息，分析不同场所、人群的核酸检测情况，以了解场所类型和人群特征对核酸检测的影响。\n",
    "分析采样和检测时间与其他表的时间信息，如扫码记录时间和自查上报时间，以了解时间因素在核酸检测过程中的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "五个数据表的结构和内容，分别为：场所信息表、个人自查上报信息表、扫码记录表、核酸采样记录表和体温测量记录表。\n",
    "\n",
    "场所信息表：包含了场所的 ID、名称、类型、坐标和记录创建时间等信息。可以通过此表了解不同类型场所的分布情况。\n",
    "\n",
    "个人自查上报信息表：包含了自查记录序列号、人员 ID、症状、核酸检测结果、居住情况、上报地点坐标和上报时间等信息。可以通过此表了解人员的自查症状和核酸检测结果等情况。\n",
    "\n",
    "扫码记录表：包含了扫码记录序列号、场所 ID、人员 ID、体温和记录创建时间等信息。可以通过此表了解人员在不同场所的扫码记录和体温情况。\n",
    "\n",
    "核酸采样记录表：包含了采样记录序列号、人员 ID、采样时间、检测时间、检测结果和场所 ID 等信息。可以通过此表了解人员的核酸采样和检测情况。\n",
    "\n",
    "体温测量记录表：包含了测量记录序列号、场所 ID、人员 ID、体温和记录创建时间等信息。可以通过此表了解人员的体温测量情况。\n",
    "\n",
    "\n",
    "为了更深入地了解疫情状况，我们可以将这些表进行关联分析，比如分析不同类型场所中人员的症状、核酸检测结果和体温情况，或者结合时间因素分析疫情的发展趋势等。这些分析结果可以为疫情防控提供有价值的参考。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对 df_people 数据进行清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T12:08:43.218546Z",
     "start_time": "2023-04-18T12:08:42.030694Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: data/all/附件2.csv\n",
      "清洗前的数据量: 99996\n",
      "100岁以上：13\n",
      "115岁以上：13\n",
      "处理gender缺失值前后数量变化: 31 -> 0\n",
      "处理birthdate缺失值前后数量变化: 3 -> 0\n",
      "处理年龄与birthdate和create_time不匹配的行前后数量变化: 99966 -> 99965\n",
      "重复的openid数量: 1968\n",
      "重复的user_id数量: 0\n",
      "重复的create_time数量: 154\n",
      "清洗后的数据量: 97921\n"
     ]
    }
   ],
   "source": [
    "df_people = read_file('data/all/附件2.csv')\n",
    "print(f\"清洗前的数据量: {df_people.shape[0]}\")\n",
    "\n",
    "# 删除年龄异常值\n",
    "print(f\"100岁以上：{(df_people['age'] > 100).sum()}\\n115岁以上：{(df_people['age'] > 115).sum()}\")\n",
    "df_people = df_people[(df_people['age'] >= 0) & (df_people['age'] <= 115)]\n",
    "\n",
    "# 用众数填充性别缺失值\n",
    "col = 'gender'\n",
    "missing_values_before = df_people[col].isna().sum()\n",
    "df_people[col].fillna(df_people[col].mode()[0], inplace=True)\n",
    "missing_values_after = df_people[col].isna().sum()\n",
    "print(f\"处理{col}缺失值前后数量变化: {missing_values_before} -> {missing_values_after}\")\n",
    "\n",
    "# 处理birthdate缺失值\n",
    "col = 'birthdate'\n",
    "missing_values_before = df_people[col].isna().sum()\n",
    "current_year = pd.to_datetime('today').year\n",
    "df_people.loc[df_people[col].isna(), col] = df_people.loc[df_people[col].isna(), 'age'].apply(lambda x: pd.Timestamp(year=int(current_year-x), month=1, day=1))\n",
    "missing_values_after = df_people[col].isna().sum()\n",
    "print(f\"处理{col}缺失值前后数量变化: {missing_values_before} -> {missing_values_after}\")\n",
    "\n",
    "\n",
    "# 转换birthdate列的数据类型为日期类型\n",
    "df_people['birthdate'] = pd.to_datetime(df_people['birthdate'])\n",
    "# 转换create_time列的数据类型为日期类型\n",
    "df_people['create_time'] = pd.to_datetime(df_people['create_time'])\n",
    "\n",
    "# 删除年龄与birthdate和create_time不匹配的行\n",
    "mismatch_before = df_people.shape[0]\n",
    "df_people['year_difference'] = (df_people['create_time'] - df_people['birthdate']).dt.days // 365\n",
    "df_people = df_people[abs(df_people['year_difference'] - df_people['age']) <= 2]\n",
    "mismatch_after = df_people.shape[0]\n",
    "print(f\"处理年龄与birthdate和create_time不匹配的行前后数量变化: {mismatch_before} -> {mismatch_after}\")\n",
    "df_people.drop(columns=['year_difference'], inplace=True)\n",
    "\n",
    "# 计算重复值并在处理过程中输出\n",
    "for col in ['openid', 'user_id', 'create_time']:\n",
    "    duplicate_values = df_people[df_people[col].duplicated(keep=False)]\n",
    "    print(f\"重复的{col}数量: {duplicate_values.shape[0]}\")\n",
    "    df_people = df_people[~df_people[col].duplicated(keep='first')]\n",
    "\n",
    "# 保存清洗后的数据\n",
    "df_people.to_csv('data/cleaned/人员信息表.csv', index=False)\n",
    "\n",
    "# 输出清洗后的数据量\n",
    "print(f\"清洗后的数据量: {df_people.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对 df_place 数据进行清洗（数据干净）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T02:37:39.056466Z",
     "start_time": "2023-04-18T02:37:39.002095Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: data/all/附件3.csv\n",
      "缺失值情况：\n",
      "grid_point_id    0\n",
      "name             0\n",
      "point_type       0\n",
      "x_coordinate     0\n",
      "y_coordinate     0\n",
      "create_time      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_place = read_file('data/all/附件3.csv')\n",
    "\n",
    "# 将create_time转换为日期类型\n",
    "df_place['create_time'] = pd.to_datetime(df_place['create_time'])\n",
    "\n",
    "# 删除重复行\n",
    "df_place = df_place.drop_duplicates()\n",
    "\n",
    "# 检查是否有缺失值\n",
    "print(\"缺失值情况：\")\n",
    "print(df_place.isnull().sum())\n",
    "\n",
    "# 如果有缺失值，可以考虑删除缺失值所在的行或使用合适的方法填充缺失值\n",
    "# 假设这里没有缺失值，无需处理\n",
    "\n",
    "# 保存清洗后的数据到新的CSV文件\n",
    "df_place.to_csv('data/cleaned/场所信息表.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对 df_self_check 数据进行清洗（数据干净）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T02:37:44.074235Z",
     "start_time": "2023-04-18T02:37:43.608053Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: data/all/附件4.csv\n",
      "缺失值情况：\n",
      "sno                     0\n",
      "user_id                 0\n",
      "x_coordinate            0\n",
      "y_coordinate            0\n",
      "symptom                 0\n",
      "nucleic_acid_result     0\n",
      "resident_flag           0\n",
      "dump_time               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_self_check = read_file('data/all/附件4.csv')\n",
    "# 将dump_time转换为日期类型\n",
    "df_self_check['dump_time'] = pd.to_datetime(df_self_check['dump_time'])\n",
    "\n",
    "# 删除重复行\n",
    "df_self_check = df_self_check.drop_duplicates()\n",
    "\n",
    "# 检查缺失值\n",
    "print(\"缺失值情况：\")\n",
    "print(df_self_check.isnull().sum())\n",
    "\n",
    "# 处理异常值（如果有）\n",
    "# 例如：处理年龄为负数的异常值\n",
    "# df_self_check = df_self_check[df_self_check['age'] >= 0]\n",
    "\n",
    "# 保存清洗后的数据到新的CSV文件\n",
    "df_self_check.to_csv('data/cleaned/个人自查上报信息表.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对 df_scan 数据进行清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T11:13:20.914645Z",
     "start_time": "2023-04-18T11:10:51.581733Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: data/all/附件5\\20221001.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 194 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221001.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221002.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 37691 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221002.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221003.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 29640 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221003.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221004.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 20667 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221004.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221005.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 22260 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221005.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221006.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 439 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221006.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221007.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 25790 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221007.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221008.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 16418 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221008.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221009.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 23148 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221009.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221010.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 25723 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221010.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221011.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 34724 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221011.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221012.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 3190 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221012.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221013.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 36860 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221013.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221014.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 48257 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221014.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221015.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 11171 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221015.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221016.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 7725 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221016.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221017.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 11396 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221017.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221018.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 39446 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221018.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221019.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 13417 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221019.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221020.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 49917 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221020.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221021.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 0 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221021.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221022.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 14182 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221022.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221023.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 31307 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221023.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221024.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 13400 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221024.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221025.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 14627 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221025.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221026.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 32488 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221026.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221027.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 43088 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221027.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221028.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 29606 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221028.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221029.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 45175 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221029.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221030.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 7238 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221030.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221031.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 41585 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221031.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221101.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 469 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221101.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221102.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 30908 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221102.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221103.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 14330 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221103.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221104.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 5489 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221104.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221105.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 23513 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221105.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221106.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 3887 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221106.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221107.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 26053 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221107.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221108.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 19111 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221108.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221109.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 34131 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221109.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221110.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 2 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221110.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221111.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 18260 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221111.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221112.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 39957 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221112.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221113.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 26887 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221113.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221114.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 23517 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221114.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221115.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 9831 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221115.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221116.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 44599 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221116.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221117.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 27767 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221117.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221118.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 42976 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221118.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221119.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 21974 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221119.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221120.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 27073 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221120.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221121.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 47433 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221121.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221122.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 63 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221122.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221123.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 46446 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221123.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221124.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 18283 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221124.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221125.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 22465 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221125.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221126.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 7839 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221126.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221127.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 14953 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221127.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221128.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 38169 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221128.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221129.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 20676 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221129.csv\n",
      "\n",
      "Reading file: data/all/附件5\\20221130.csv\n",
      "处理缺失值前后数量变化: 0 -> 0\n",
      "处理重复值前后数量变化: 0 -> 0\n",
      "处理异常体温值前后数量变化: 0 -> 0\n",
      "处理日期不匹配的行前后数量变化: 26286 -> 0\n",
      "已保存清洗后的数据到文件: data\\cleaned\\场所扫码信息表\\20221130.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "file_list = glob.glob('data/all/附件5/*.csv')\n",
    "\n",
    "for file_path in file_list:\n",
    "    df_scan = read_file(file_path)\n",
    "    df_scan['create_time'] = pd.to_datetime(df_scan['create_time'])\n",
    "\n",
    "    missing_values_before = df_scan.isnull().sum().sum()\n",
    "    df_scan = df_scan.dropna()\n",
    "    missing_values_after = df_scan.isnull().sum().sum()\n",
    "    print(f\"处理缺失值前后数量变化: {missing_values_before} -> {missing_values_after}\")\n",
    "\n",
    "    # 处理重复值\n",
    "    duplicates_before = df_scan.duplicated(subset=['user_id', 'grid_point_id', 'create_time']).sum()\n",
    "    df_scan = df_scan.drop_duplicates(subset=['user_id', 'grid_point_id', 'create_time'], keep='first')\n",
    "    duplicates_after = df_scan.duplicated(subset=['user_id', 'grid_point_id', 'create_time']).sum()\n",
    "    print(f\"处理重复值前后数量变化: {duplicates_before} -> {duplicates_after}\")\n",
    "\n",
    "    # 处理异常值，体温范围\n",
    "    temp_outliers_before = ((df_scan['temperature'] < 35.0) | (df_scan['temperature'] > 42.0)).sum()\n",
    "    df_scan = df_scan[(df_scan['temperature'] >= 35.0) & (df_scan['temperature'] <= 42.0)]\n",
    "    temp_outliers_after = ((df_scan['temperature'] < 35.0) | (df_scan['temperature'] > 42.0)).sum()\n",
    "    print(f\"处理异常体温值前后数量变化: {temp_outliers_before} -> {temp_outliers_after}\")\n",
    "    # 删除与文件名中日期不匹配的行\n",
    "    date_pattern = r'\\d{8}'\n",
    "    date_str = re.search(date_pattern, file_path).group(0)\n",
    "    file_date = datetime.strptime(date_str, '%Y%m%d').date()\n",
    "    date_mismatch_before = (df_scan['create_time'].dt.date != file_date).sum()\n",
    "    df_scan = df_scan[df_scan['create_time'].dt.date == file_date]\n",
    "    date_mismatch_after = (df_scan['create_time'].dt.date != file_date).sum()\n",
    "    print(f\"处理日期不匹配的行前后数量变化: {date_mismatch_before} -> {date_mismatch_after}\")\n",
    "\n",
    "\n",
    "    # 保存清洗后的数据到新的CSV文件\n",
    "    cleaned_file_path = os.path.join('data', 'cleaned', '场所扫码信息表',os.path.basename(file_path))\n",
    "    df_scan.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"已保存清洗后的数据到文件: {cleaned_file_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对 df_na_check 数据进行清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T02:43:47.532890Z",
     "start_time": "2023-04-18T02:43:17.386201Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: data/all/附件6.csv\n",
      "缺失值情况：\n",
      "sno              0\n",
      "user_id          0\n",
      "cysj             0\n",
      "jcsj             0\n",
      "jg               0\n",
      "grid_point_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_na_check = read_file('data/all/附件6.csv')\n",
    "\n",
    "# 将cysj和jcsj转换为日期类型\n",
    "df_na_check['cysj'] = pd.to_datetime(df_na_check['cysj'])\n",
    "df_na_check['jcsj'] = pd.to_datetime(df_na_check['jcsj'])\n",
    "\n",
    "# 删除重复行\n",
    "df_na_check = df_na_check.drop_duplicates()\n",
    "\n",
    "# 检查缺失值\n",
    "print(\"缺失值情况：\")\n",
    "print(df_na_check.isnull().sum())\n",
    "\n",
    "# 处理异常值（如果有）\n",
    "# 例如：处理jcsj早于cysj的异常值\n",
    "df_na_check = df_na_check[df_na_check['jcsj'] >= df_na_check['cysj']]\n",
    "\n",
    "# 保存清洗后的数据到新的CSV文件\n",
    "df_na_check.to_csv('data/cleaned/核酸检测信息表.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对 df_vaccine 数据进行清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T02:51:42.356068Z",
     "start_time": "2023-04-18T02:51:39.524274Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: data/all/附件7.csv\n",
      "处理缺失值前后数量变化: 1107 -> 0\n",
      "处理重复值前后数量变化: 160 -> 0\n",
      "处理异常年龄值前后数量变化: 33 -> 0\n"
     ]
    }
   ],
   "source": [
    "df_vaccine = read_file('data/all/附件7.csv')\n",
    "\n",
    "# 处理缺失值\n",
    "missing_values_before = df_vaccine.isnull().sum().sum()\n",
    "df_vaccine = df_vaccine.dropna(subset=['inject_sn', 'user_id', 'age', 'gender', 'birthdate', 'inject_date', 'inject_times', 'vaccine_type'])\n",
    "missing_values_after = df_vaccine.isnull().sum().sum()\n",
    "print(f\"处理缺失值前后数量变化: {missing_values_before} -> {missing_values_after}\")\n",
    "\n",
    "# 检查并处理重复值\n",
    "duplicates_before = df_vaccine.duplicated(subset=['inject_sn']).sum()\n",
    "df_vaccine = df_vaccine.drop_duplicates(subset=['inject_sn'], keep='first')\n",
    "duplicates_after = df_vaccine.duplicated(subset=['inject_sn']).sum()\n",
    "print(f\"处理重复值前后数量变化: {duplicates_before} -> {duplicates_after}\")\n",
    "\n",
    "# 检查并处理异常值，如：年龄、疫苗类型、接种次数等\n",
    "age_outliers_before = ((df_vaccine['age'] < 0) | (df_vaccine['age'] > 120)).sum()\n",
    "df_vaccine = df_vaccine[(df_vaccine['age'] >= 0) & (df_vaccine['age'] <= 120)]\n",
    "age_outliers_after = ((df_vaccine['age'] < 0) | (df_vaccine['age'] > 120)).sum()\n",
    "print(f\"处理异常年龄值前后数量变化: {age_outliers_before} -> {age_outliers_after}\")\n",
    "\n",
    "# 将日期列转换为 datetime 类型\n",
    "df_vaccine['birthdate'] = pd.to_datetime(df_vaccine['birthdate'])\n",
    "df_vaccine['inject_date'] = pd.to_datetime(df_vaccine['inject_date'])\n",
    "\n",
    "# 保存清洗后的数据到新的CSV文件\n",
    "df_vaccine.to_csv('data/cleaned/疫苗接种信息表.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据整合：将关联的表进行合并，例如将场所扫码信息表与场所信息表、人员信息表和个人自查上报信息表进行合并，方便后续分析。\n",
    "\n",
    "特征工程：根据业务需求，从原始数据中提取、构建有意义的特征，例如从时间信息中提取星期、小时等时间特征，计算每个人在不同场所的扫码次数等。\n",
    "\n",
    "数据分析：对整合后的数据进行描述性统计、可视化等探索性数据分析，以了解数据的基本情况、发现数据中的规律和异常。\n",
    "\n",
    "建模预测：基于数据分析的结果，选择合适的模型进行训练，以解决实际问题，例如预测某个人员是否感染、预测核酸检测结果等。\n",
    "\n",
    "模型评估与优化：评估模型的性能，如准确率、召回率等，并通过调整模型参数、特征选择等方法进行优化。\n",
    "\n",
    "结果呈现：将分析结果以可视化、报告等形式呈现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据整合并提取特征\n",
    "df_na_check = read_file('data/all/附件6.csv')\n",
    "file_list = glob.glob('data/all/附件5/*.csv')\n",
    "df_scan = pd.concat([read_file(file) for file in file_list])\n",
    "df_scan['create_time'] = pd.to_datetime(df_scan['create_time'])\n",
    "df_people = read_file('data/all/附件2.csv')\n",
    "df_place = read_file('data/all/附件3.csv')\n",
    "df_self_check = read_file('data/all/附件4.csv')\n",
    "df_self_check['dump_time'] = pd.to_datetime(df_self_check['dump_time'])\n",
    "\n",
    "# 数据整合\n",
    "df_scan_place = pd.merge(df_scan, df_place, on='grid_point_id', suffixes=('_scan', '_place'))\n",
    "df_self_check_people = pd.merge(df_self_check, df_people, on='user_id', suffixes=('_self_check', '_people'))\n",
    "\n",
    "# 特征工程\n",
    "# 提取扫码时间的小时特征\n",
    "df_scan_place['hour'] = df_scan_place['create_time'].dt.hour\n",
    "\n",
    "# 计算每个人在不同场所的扫码次数\n",
    "scan_count_by_user_place = df_scan_place.groupby(['user_id', 'grid_point_id']).size().reset_index(name='scan_count')\n",
    "\n",
    "# 合并特征到主数据集\n",
    "df_scan_place = pd.merge(df_scan_place, scan_count_by_user_place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据分析时可以做以下可视化**\n",
    "\n",
    "**单表可视化**\n",
    "\n",
    "1. 人员信息表：可以进行人口统计学分析，如性别、年龄、民族等分布情况，还可以通过人员 ID 与其他表格进行关联分析。\n",
    "\n",
    "2. 场所信息表：可以进行地理信息分析，如场所分布情况、场所类型分布情况、场所密度等分析。\n",
    "\n",
    "3. 个人自查上报信息表：可以进行疫情监测分析，如症状分布情况、症状与核酸检测结果的关联分析、上报人员的位置分布情况等分析。\n",
    "\n",
    "4. 场所码扫码信息表：可以进行疫情监测分析，如扫码记录分布情况、扫码记录与核酸检测结果的关联分析等。\n",
    "\n",
    "5. 核酸采样检测信息表：可以进行疫情监测分析，如阳性人员的分布情况、核酸检测阳性率分析、阳性人员的接触场所与密切接触者分析等。\n",
    "\n",
    "\n",
    "**关联分析**\n",
    "\n",
    "1. 个人自查上报信息表和核酸采样检测信息表：可以分析个人上报的症状与核酸检测结果之间的关系，以及症状与检测结果对不同年龄、性别、民族等人群的影响。\n",
    "\n",
    "2. 场所信息表和场所码扫码信息表：可以分析不同场所的扫码情况，了解人们在哪些场所更容易扫码；也可以分析场所内体温异常者的情况，了解哪些场所的防疫工作存在漏洞。\n",
    "\n",
    "3. 个人自查上报信息表和场所码扫码信息表：可以根据个人自查上报的症状，分析不同场所的症状发生情况，了解哪些场所的防疫措施需要进一步加强。\n",
    "\n",
    "4. 核酸采样检测信息表和个人自查上报信息表、场所码扫码信息表：可以分析阳性人员的出行情况，追踪密接者，及时采取隔离措施。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：确定每个场所的温度分布的平均值和标准偏差\n",
    "df_scan['temperature_mean'] = df_scan.groupby('grid_point_id')['temperature'].transform('mean') #平均值\n",
    "df_scan['temperature_std'] = df_scan.groupby('grid_point_id')['temperature'].transform('std') #方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sno  grid_point_id  user_id  temperature         create_time  \\\n",
      "0          283           2285    10063         37.2 2022-10-01 18:50:02   \n",
      "1          284           2649    10063         36.9 2022-10-01 17:34:02   \n",
      "2          285           2232    10063         37.2 2022-10-01 19:10:02   \n",
      "3          291           1439    10063         36.7 2022-10-02 11:28:11   \n",
      "4          292           2070    10063         36.9 2022-10-02 16:23:11   \n",
      "...        ...            ...      ...          ...                 ...   \n",
      "231068  317859           1305    79358         37.1 2022-11-29 17:26:49   \n",
      "231069  317850            214    79358         35.7 2022-11-30 08:57:03   \n",
      "231070  317851           2766    79358         36.2 2022-11-30 12:21:03   \n",
      "231071  317852             49    79358         35.9 2022-11-30 15:32:03   \n",
      "231072  317853           2170    79358         37.0 2022-11-30 19:15:03   \n",
      "\n",
      "        temperature_mean  temperature_std  temperature_mean_positive  \n",
      "0              36.453399         0.434601                  36.412789  \n",
      "1              36.457131         0.435244                  36.440708  \n",
      "2              36.449200         0.434978                  36.433194  \n",
      "3              36.449849         0.433937                  36.416429  \n",
      "4              36.449802         0.437242                  36.605405  \n",
      "...                  ...              ...                        ...  \n",
      "231068         36.441541         0.428420                  36.669565  \n",
      "231069         36.442236         0.433301                  36.390217  \n",
      "231070         36.453369         0.430630                  36.438462  \n",
      "231071         36.450288         0.434596                  36.465825  \n",
      "231072         36.457478         0.436069                  36.284211  \n",
      "\n",
      "[231073 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#根据场所码扫码信息表和核酸采样信息表，确定感染者的平均体温\n",
    "#df_na_check是另一个数据框，其中包含有关用户的信息，包括他们是否对某种疾病进行了阳性或阴性测试。这里，df_na_check['jg'] == '阳性用于过滤出仅对该疾病测试呈阳性的用户。然后，[['user_id']]被用来仅选择从过滤后的df_na_check数据框中的'user_id'列。\n",
    "#使用pd.merge将df_scan和过滤后的df_na_check数据框基于'user_id'列进行连接，只有在结果数据框df_positive中有匹配'user_id'值的行被包含进来。\n",
    "#最后，使用df_positive.groupby('grid_point_id')['temperature'].transform('mean')计算具有相同'grid_point_id'值的行组的平均温度值。结果是一个名为'temperature_mean_positive'的新列，其中包含了df_positive数据框中每个行组的平均温度值。\n",
    "#因此，这段代码创建了一个名为df_positive的新数据框，其中包含了仅对某种疾病测试呈阳性的用户的df_scan行，并计算了每个行组的平均温度值，并将这些信息作为新列添加到了df_positive数据框中。\n",
    "df_positive = pd.merge(df_scan, df_na_check[df_na_check['jg'] == '阳性'][['user_id']], on='user_id', how='inner')\n",
    "df_positive['temperature_mean_positive'] = df_positive.groupby('grid_point_id')['temperature'].transform('mean')\n",
    "print(df_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sno  grid_point_id  user_id  temperature         create_time  \\\n",
      "0          283           2285    10063         37.2 2022-10-01 18:50:02   \n",
      "1          284           2649    10063         36.9 2022-10-01 17:34:02   \n",
      "2          285           2232    10063         37.2 2022-10-01 19:10:02   \n",
      "3          291           1439    10063         36.7 2022-10-02 11:28:11   \n",
      "4          292           2070    10063         36.9 2022-10-02 16:23:11   \n",
      "...        ...            ...      ...          ...                 ...   \n",
      "231068  317859           1305    79358         37.1 2022-11-29 17:26:49   \n",
      "231069  317850            214    79358         35.7 2022-11-30 08:57:03   \n",
      "231070  317851           2766    79358         36.2 2022-11-30 12:21:03   \n",
      "231071  317852             49    79358         35.9 2022-11-30 15:32:03   \n",
      "231072  317853           2170    79358         37.0 2022-11-30 19:15:03   \n",
      "\n",
      "        temperature_mean  temperature_std  temperature_mean_positive  \\\n",
      "0              36.453399         0.434601                  36.412789   \n",
      "1              36.457131         0.435244                  36.440708   \n",
      "2              36.449200         0.434978                  36.433194   \n",
      "3              36.449849         0.433937                  36.416429   \n",
      "4              36.449802         0.437242                  36.605405   \n",
      "...                  ...              ...                        ...   \n",
      "231068         36.441541         0.428420                  36.669565   \n",
      "231069         36.442236         0.433301                  36.390217   \n",
      "231070         36.453369         0.430630                  36.438462   \n",
      "231071         36.450288         0.434596                  36.465825   \n",
      "231072         36.457478         0.436069                  36.284211   \n",
      "\n",
      "        infection_prob  \n",
      "0             0.995644  \n",
      "1             0.999288  \n",
      "2             0.999323  \n",
      "3             0.997039  \n",
      "4             0.938640  \n",
      "...                ...  \n",
      "231068        0.867932  \n",
      "231069        0.992820  \n",
      "231070        0.999401  \n",
      "231071        0.999361  \n",
      "231072        0.924096  \n",
      "\n",
      "[231073 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#这段代码是在前面的代码基础上进行计算，它将计算结果添加到了df_positive数据框中的新一列infection_prob中。\n",
    "#具体来说，np.exp()是numpy库中的一个函数，它返回e的x次方。在这里，它被用于计算指数值。\n",
    "#接下来，代码中的数学公式((df_positive['temperature_mean_positive'] - df_positive['temperature_mean']) ** 2) / (2 * df_positive['temperature_std'] ** 2)用于计算指数中的底数。它计算了两个温度均值之间的平方差，并除以两个温度标准差的平方之和，从而得到一个浮点数。\n",
    "#最后，这个浮点数作为指数的底数被传递给np.exp()函数中，从而得到最终的infection_prob值。这个值表示在特定条件下，用户被感染的概率。\n",
    "###这个计算公式的目的是通过测量阳性用户体温与所有用户体温的差异，来推测用户是否被感染。这个差异越大，表示阳性用户体温相对于所有用户的体温有着更大的偏离，从而意味着阳性用户更可能被感染。\n",
    "###具体地，这个公式计算的是两个均值之间的平方差，然后除以两个标准差的平方之和。这个值表示阳性用户体温相对于所有用户的体温的差异程度，差异越大，值越大，从而表示用户被感染的概率也越大。\n",
    "df_positive['infection_prob'] = np.exp(-((df_positive['temperature_mean_positive'] - df_positive['temperature_mean']) ** 2) / (2 * df_positive['temperature_std'] ** 2))\n",
    "print(df_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          序号  密接者ID_x                 密接日期  密接场所ID  阳性人员ID  密接者数量  平均接触人数  \\\n",
      "0          1    64306  2022-11-19 14:47:33     520   78049     22    22.0   \n",
      "1          1    64306  2022-11-19 14:47:33     520   78049     22    22.0   \n",
      "2          1    64306  2022-11-19 14:47:33     520   78049     22    22.0   \n",
      "3          1    64306  2022-11-19 14:47:33     520   78049     22    22.0   \n",
      "4          1    64306  2022-11-19 14:47:33     520   78049     22    22.0   \n",
      "...      ...      ...                  ...     ...     ...    ...     ...   \n",
      "343747  1291    44049  2022-11-04 12:23:33    2040    5415      3     3.0   \n",
      "343748  1291    44049  2022-11-04 12:23:33    2040    5415      3     3.0   \n",
      "343749  1291    44049  2022-11-04 12:23:33    2040    5415      3     3.0   \n",
      "343750  1291    44049  2022-11-04 12:23:33    2040    5415      3     3.0   \n",
      "343751  1291    44049  2022-11-04 12:23:33    2040    5415      3     3.0   \n",
      "\n",
      "           sno  grid_point_id  user_id  temperature         create_time  \\\n",
      "0       294502           2729    78049         37.1 2022-10-01 06:30:40   \n",
      "1       294503           2769    78049         37.1 2022-10-01 08:06:40   \n",
      "2       294504           2667    78049         36.3 2022-10-01 10:33:40   \n",
      "3       294505           2704    78049         36.7 2022-10-01 12:30:40   \n",
      "4       295411           2638    78049         36.4 2022-10-02 22:12:37   \n",
      "...        ...            ...      ...          ...                 ...   \n",
      "343747  201895             49     5415         36.7 2022-11-29 12:41:58   \n",
      "343748  202404            161     5415         36.3 2022-11-30 21:17:37   \n",
      "343749  202405           1234     5415         36.8 2022-11-30 14:59:37   \n",
      "343750  202406             49     5415         36.6 2022-11-30 18:23:37   \n",
      "343751  202407           2021     5415         36.1 2022-11-30 21:34:37   \n",
      "\n",
      "        temperature_mean  temperature_std  temperature_mean_positive  \\\n",
      "0              36.452615         0.440610                  36.524390   \n",
      "1              36.459818         0.437391                  36.456818   \n",
      "2              36.451105         0.435835                  36.400000   \n",
      "3              36.449069         0.435671                  36.445751   \n",
      "4              36.449653         0.434935                  36.427305   \n",
      "...                  ...              ...                        ...   \n",
      "343747         36.450288         0.434596                  36.465825   \n",
      "343748         36.453319         0.434781                  36.430172   \n",
      "343749         36.446407         0.430062                  36.476296   \n",
      "343750         36.450288         0.434596                  36.465825   \n",
      "343751         36.443943         0.435349                  36.359459   \n",
      "\n",
      "        infection_prob  \n",
      "0             0.986820  \n",
      "1             0.999976  \n",
      "2             0.993149  \n",
      "3             0.999971  \n",
      "4             0.998681  \n",
      "...                ...  \n",
      "343747        0.999361  \n",
      "343748        0.998584  \n",
      "343749        0.997588  \n",
      "343750        0.999361  \n",
      "343751        0.981347  \n",
      "\n",
      "[343752 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "#将result1数据框按照['阳性人员ID', '密接场所ID']两列进行分组，统计了每个阳性人员在每个密接场所中的密接者数量，并将统计结果保存到了grouped数据框中。\n",
    "grouped = result1.groupby(['阳性人员ID', '密接场所ID'])['密接者ID'].count().reset_index()\n",
    "#接下来，将grouped数据框与result1数据框进行左连接，并将结果保存到result1_count数据框中。这个连接操作的目的是将每个阳性人员在每个密接场所中的密接者数量添加到原数据集result1中。\n",
    "result1 = pd.merge(result1, grouped, on=['阳性人员ID', '密接场所ID'], how='left')\n",
    "result1_count = result1.rename(columns={'密接者ID_y': '密接者数量'})\n",
    "result1_count['平均接触人数'] = result1_count.groupby(['阳性人员ID', '密接场所ID'])['密接者数量'].transform('mean')\n",
    "#最后，将result1_count数据框与df_positive数据框进行连接，并将结果保存到df_positive数据框中。这个连接操作的目的是将每个阳性人员在每个密接场所中的密接者数量和平均接触人数添加到df_positive数据框中，以便后续分析。\n",
    "df_positive = pd.merge(result1_count, df_positive, left_on='阳性人员ID', right_on='user_id')\n",
    "print(df_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这段代码的作用是为df_positive数据框添加一列名为label的新列，该列的值是df_positive数据框中infection_prob和平均接触人数两列的乘积。infection_prob表示该用户被感染的概率，平均接触人数表示该用户平均接触的人数。因此，label列的值表示该用户在疫情传播中的风险值。如果label的值越大，则表示该用户在疫情传播中的风险越高。\n",
    "df_positive['label'] = df_positive['infection_prob'] * df_positive['平均接触人数']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: cleaned/疫苗接种信息表.csv\n"
     ]
    }
   ],
   "source": [
    "# 疫苗接种信息表\n",
    "df_vaccine_info = read_file('cleaned/疫苗接种信息表.csv')\n",
    "df = pd.merge(df_vaccine_info, df_positive, on='user_id')\n",
    "# 去除没有label的数据\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['age', 'gender','inject_times', 'vaccine_type','label']\n",
    "df = df[col]\n",
    "#这段代码导入了两个Python库：sklearn.preprocessing和sklearn.ensemble。其中，LabelEncoder是一个用于对标签进行编码的类，RandomForestRegressor是一个随机森林回归器，用于对数据进行回归分析。\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 创建 LabelEncoder 对象\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 对 inject_times 和 vaccine_type 进行数值编码\n",
    "df['inject_times'] = le.fit_transform(df['inject_times'])\n",
    "df['vaccine_type'] = le.fit_transform(df['vaccine_type'])\n",
    "\n",
    "# 创建随机森林回归模型\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=2023)\n",
    "# 拟合数据\n",
    "X= df.drop('label',axis=1)\n",
    "y = df['label']\n",
    "rf.fit(X, y)\n",
    "\n",
    "#这段代码计算了一个名为importances的变量，该变量存储了随机森林回归器rf中每个特征的重要性分数。随机森林回归器可以用于特征选择，feature_importances_属性可以返回每个特征的重要性分数，这些分数可以用于确定哪些特征对预测结果影响最大。importances变量是一个包含了每个特征重要性分数的数组。\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# 将特征重要性排序\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# 将特征名称按照重要性排序\n",
    "names = [f'Feature {i}' for i in range(X.shape[1])]\n",
    "sorted_names = [names[i] for i in indices]\n",
    "\n",
    "# 绘制特征重要性柱状图\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), sorted_names, rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
